{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubert Stefanski - Data Mining II - Main Assignment\n",
    "## 20081102@mail.wit.ie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "plt.style.use(\"seaborn-darkgrid\")\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and globals\n",
    "don't mind this, I'm just lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_func(df):\n",
    "    col_names = []\n",
    "    for i in range(df.shape[1]):\n",
    "        col_names.append(\"Col_\" + str(i))\n",
    "    return col_names\n",
    "\n",
    "SEED = 64\n",
    "TARGET = \"Target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled (16000, 177)\n",
      "Scoring (9000, 176)\n"
     ]
    }
   ],
   "source": [
    "# Load and name columns, change last column name to \"Target\"\n",
    "df_labeled = pd.read_csv(\"data/labeled.csv.gz\",names = name_func(pd.read_csv(\"data/labeled.csv.gz\")))\n",
    "df_labeled.columns = [*df_labeled.columns[:-1],\"Target\"]\n",
    "print(\"Labeled\", df_labeled.shape)\n",
    "# df_labeled.head()\n",
    "\n",
    "# Load and name columns\n",
    "df_scoring = pd.read_csv(\"data/scoring.csv.gz\",names = name_func(pd.read_csv(\"data/scoring.csv.gz\")))\n",
    "print(\"Scoring\", df_scoring.shape)\n",
    "# df_scoring.head()\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan exists?: True\n",
      "NaN count: 3365\n",
      "Nan exists?: False\n",
      "NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "# Change categorical data to binary flag\n",
    "for col in df_labeled.select_dtypes(include=['object']).copy():\n",
    "    df_labeled[col] = df_labeled[col].str.lower()\n",
    "    encoder = OrdinalEncoder(categories=[['no','yes']])\n",
    "    df_labeled[col] = encoder.fit_transform(df_labeled.loc[:,[col]])\n",
    "\n",
    "# Check whether NaNs exist\n",
    "print(\"Nan exists?: \" + str(df_labeled.isnull().values.any()))\n",
    "\n",
    "# Check total number of NaNs\n",
    "print(\"NaN count: \" + str(df_labeled.isnull().sum().sum()))\n",
    "\n",
    "# Cleanup NaNs\n",
    "for col in df_labeled.columns:\n",
    "    if df_labeled[col].isna().values.any():\n",
    "        # Replace all NaNs with means of the column\n",
    "        df_labeled[col] = df_labeled[col].fillna(df_labeled[col].mode().values[0])\n",
    "\n",
    "# Check whether NaNs exist after nan Cleanup      \n",
    "print(\"Nan exists?: \" + str(df_labeled.isnull().values.any()))\n",
    "# Check total number of NaNs\n",
    "print(\"NaN count: \" + str(df_labeled.isnull().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting dTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    159\n",
       "int64       18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "no need to fix dtypes, all int64 and float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical/Numerical split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Categorical count: 29 and \\n Numerical count:143'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names as list\n",
    "attributes = df_labeled.columns.tolist()\n",
    "# Remove the target column, no point in doing this if we include it\n",
    "attributes.remove(TARGET)\n",
    "\n",
    "temp = df_labeled[attributes].nunique()\n",
    "\n",
    "categorical = list(temp[(temp>1)& (temp<20)].index)\n",
    "\n",
    "numerical = list(temp[(temp>20)].index)\n",
    "\n",
    "f\"Categorical count: {len(categorical)} and \\n Numerical count:{len(numerical)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the cleaned up DataFrame to a fresh csv\n",
    "This allows some insight through dTale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.to_csv(\"output/clean_df_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 177) (6400, 177)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_labeled,stratify= df_labeled[TARGET], test_size=.4, random_state=SEED)\n",
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_0</th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "      <th>Col_3</th>\n",
       "      <th>Col_4</th>\n",
       "      <th>Col_5</th>\n",
       "      <th>Col_6</th>\n",
       "      <th>Col_7</th>\n",
       "      <th>Col_8</th>\n",
       "      <th>Col_9</th>\n",
       "      <th>Col_10</th>\n",
       "      <th>Col_11</th>\n",
       "      <th>Col_12</th>\n",
       "      <th>Col_13</th>\n",
       "      <th>Col_14</th>\n",
       "      <th>Col_15</th>\n",
       "      <th>Col_16</th>\n",
       "      <th>Col_17</th>\n",
       "      <th>Col_18</th>\n",
       "      <th>Col_19</th>\n",
       "      <th>Col_20</th>\n",
       "      <th>Col_21</th>\n",
       "      <th>Col_22</th>\n",
       "      <th>Col_23</th>\n",
       "      <th>Col_24</th>\n",
       "      <th>Col_25</th>\n",
       "      <th>Col_26</th>\n",
       "      <th>Col_27</th>\n",
       "      <th>Col_28</th>\n",
       "      <th>Col_29</th>\n",
       "      <th>Col_30</th>\n",
       "      <th>Col_31</th>\n",
       "      <th>Col_32</th>\n",
       "      <th>Col_33</th>\n",
       "      <th>Col_34</th>\n",
       "      <th>Col_35</th>\n",
       "      <th>Col_36</th>\n",
       "      <th>Col_37</th>\n",
       "      <th>Col_38</th>\n",
       "      <th>Col_39</th>\n",
       "      <th>Col_40</th>\n",
       "      <th>Col_41</th>\n",
       "      <th>Col_42</th>\n",
       "      <th>Col_43</th>\n",
       "      <th>Col_44</th>\n",
       "      <th>Col_45</th>\n",
       "      <th>Col_46</th>\n",
       "      <th>Col_47</th>\n",
       "      <th>Col_48</th>\n",
       "      <th>Col_49</th>\n",
       "      <th>Col_50</th>\n",
       "      <th>Col_51</th>\n",
       "      <th>Col_52</th>\n",
       "      <th>Col_53</th>\n",
       "      <th>Col_54</th>\n",
       "      <th>Col_55</th>\n",
       "      <th>Col_56</th>\n",
       "      <th>Col_57</th>\n",
       "      <th>Col_58</th>\n",
       "      <th>Col_59</th>\n",
       "      <th>Col_60</th>\n",
       "      <th>Col_61</th>\n",
       "      <th>Col_62</th>\n",
       "      <th>Col_63</th>\n",
       "      <th>Col_64</th>\n",
       "      <th>Col_65</th>\n",
       "      <th>Col_66</th>\n",
       "      <th>Col_67</th>\n",
       "      <th>Col_68</th>\n",
       "      <th>Col_69</th>\n",
       "      <th>Col_70</th>\n",
       "      <th>Col_71</th>\n",
       "      <th>Col_72</th>\n",
       "      <th>Col_73</th>\n",
       "      <th>Col_74</th>\n",
       "      <th>Col_75</th>\n",
       "      <th>Col_76</th>\n",
       "      <th>Col_77</th>\n",
       "      <th>Col_78</th>\n",
       "      <th>Col_79</th>\n",
       "      <th>Col_80</th>\n",
       "      <th>Col_81</th>\n",
       "      <th>Col_82</th>\n",
       "      <th>Col_83</th>\n",
       "      <th>Col_84</th>\n",
       "      <th>Col_85</th>\n",
       "      <th>Col_86</th>\n",
       "      <th>Col_87</th>\n",
       "      <th>Col_88</th>\n",
       "      <th>Col_89</th>\n",
       "      <th>Col_90</th>\n",
       "      <th>Col_91</th>\n",
       "      <th>Col_92</th>\n",
       "      <th>Col_93</th>\n",
       "      <th>Col_94</th>\n",
       "      <th>Col_95</th>\n",
       "      <th>Col_96</th>\n",
       "      <th>Col_97</th>\n",
       "      <th>Col_98</th>\n",
       "      <th>Col_99</th>\n",
       "      <th>Col_100</th>\n",
       "      <th>Col_101</th>\n",
       "      <th>Col_102</th>\n",
       "      <th>Col_103</th>\n",
       "      <th>Col_104</th>\n",
       "      <th>Col_105</th>\n",
       "      <th>Col_106</th>\n",
       "      <th>Col_107</th>\n",
       "      <th>Col_108</th>\n",
       "      <th>Col_109</th>\n",
       "      <th>Col_110</th>\n",
       "      <th>Col_111</th>\n",
       "      <th>Col_112</th>\n",
       "      <th>Col_113</th>\n",
       "      <th>Col_114</th>\n",
       "      <th>Col_115</th>\n",
       "      <th>Col_116</th>\n",
       "      <th>Col_117</th>\n",
       "      <th>Col_118</th>\n",
       "      <th>Col_119</th>\n",
       "      <th>Col_120</th>\n",
       "      <th>Col_121</th>\n",
       "      <th>Col_122</th>\n",
       "      <th>Col_123</th>\n",
       "      <th>Col_124</th>\n",
       "      <th>Col_125</th>\n",
       "      <th>Col_126</th>\n",
       "      <th>Col_127</th>\n",
       "      <th>Col_128</th>\n",
       "      <th>Col_129</th>\n",
       "      <th>Col_130</th>\n",
       "      <th>Col_131</th>\n",
       "      <th>Col_132</th>\n",
       "      <th>Col_133</th>\n",
       "      <th>Col_134</th>\n",
       "      <th>Col_135</th>\n",
       "      <th>Col_136</th>\n",
       "      <th>Col_137</th>\n",
       "      <th>Col_138</th>\n",
       "      <th>Col_139</th>\n",
       "      <th>Col_140</th>\n",
       "      <th>Col_141</th>\n",
       "      <th>Col_142</th>\n",
       "      <th>Col_143</th>\n",
       "      <th>Col_144</th>\n",
       "      <th>Col_145</th>\n",
       "      <th>Col_146</th>\n",
       "      <th>Col_147</th>\n",
       "      <th>Col_148</th>\n",
       "      <th>Col_149</th>\n",
       "      <th>Col_150</th>\n",
       "      <th>Col_151</th>\n",
       "      <th>Col_152</th>\n",
       "      <th>Col_153</th>\n",
       "      <th>Col_154</th>\n",
       "      <th>Col_155</th>\n",
       "      <th>Col_156</th>\n",
       "      <th>Col_157</th>\n",
       "      <th>Col_158</th>\n",
       "      <th>Col_159</th>\n",
       "      <th>Col_160</th>\n",
       "      <th>Col_161</th>\n",
       "      <th>Col_162</th>\n",
       "      <th>Col_163</th>\n",
       "      <th>Col_164</th>\n",
       "      <th>Col_165</th>\n",
       "      <th>Col_166</th>\n",
       "      <th>Col_167</th>\n",
       "      <th>Col_168</th>\n",
       "      <th>Col_169</th>\n",
       "      <th>Col_170</th>\n",
       "      <th>Col_171</th>\n",
       "      <th>Col_172</th>\n",
       "      <th>Col_173</th>\n",
       "      <th>Col_174</th>\n",
       "      <th>Col_175</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10116</th>\n",
       "      <td>60.0</td>\n",
       "      <td>22.7931</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>3</td>\n",
       "      <td>94.8683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>6</td>\n",
       "      <td>1.1989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4467.684</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>12277.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2984</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.3705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.12</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.669</td>\n",
       "      <td>26.1543</td>\n",
       "      <td>67.082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>1.1564</td>\n",
       "      <td>1.7731</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>838.4903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.134</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>67.082</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>1.1493</td>\n",
       "      <td>19.98</td>\n",
       "      <td>1.1258</td>\n",
       "      <td>33.12</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.45</td>\n",
       "      <td>15.698</td>\n",
       "      <td>0.7707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02838</td>\n",
       "      <td>9108.9</td>\n",
       "      <td>2.43</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>1407.35</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425.192</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.99</td>\n",
       "      <td>44.5266</td>\n",
       "      <td>5.5897</td>\n",
       "      <td>10.3882</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1374.1179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40484</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.224</td>\n",
       "      <td>1.0711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1327</td>\n",
       "      <td>11.7</td>\n",
       "      <td>34.38</td>\n",
       "      <td>638.55</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>1.0861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5556</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>161.19</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.545672</td>\n",
       "      <td>67.082</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>2</td>\n",
       "      <td>8.1351</td>\n",
       "      <td>6.03</td>\n",
       "      <td>3.2308</td>\n",
       "      <td>6.4568</td>\n",
       "      <td>1.1176</td>\n",
       "      <td>5590.7155</td>\n",
       "      <td>45.688</td>\n",
       "      <td>49.9053</td>\n",
       "      <td>2.328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.6222</td>\n",
       "      <td>1402</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>167.13</td>\n",
       "      <td>4.3777</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3529</td>\n",
       "      <td>3.6522</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>1.509</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Col_0    Col_1   Col_2     Col_3  Col_4   Col_5   Col_6  Col_7  \\\n",
       "10116   60.0  22.7931  0.6356  0.000516      0  1.1447  0.1093      3   \n",
       "\n",
       "         Col_8  Col_9  Col_10  Col_11  Col_12  Col_13  Col_14    Col_15  \\\n",
       "10116  94.8683    0.0  0.0889       6  1.1989     0.0    60.0  4467.684   \n",
       "\n",
       "       Col_16  Col_17  Col_18  Col_19    Col_20  Col_21  Col_22    Col_23  \\\n",
       "10116    0.63       2    29.7  0.1289  12277.62     0.0     1.0  0.002672   \n",
       "\n",
       "       Col_24  Col_25  Col_26   Col_27  Col_28  Col_29  Col_30  Col_31  \\\n",
       "10116    90.0     1.0  0.5813  0.00002     0.0     3.0     0.0    0.63   \n",
       "\n",
       "       Col_32  Col_33  Col_34    Col_35  Col_36  Col_37  Col_38   Col_39  \\\n",
       "10116    0.81   11.61     0.0  0.000168     0.0  6.2984     3.0  27.3705   \n",
       "\n",
       "       Col_40  Col_41  Col_42    Col_43  Col_44  Col_45  Col_46  Col_47  \\\n",
       "10116     0.0     0.0   60.12  0.001472     0.0       3     0.0     0.0   \n",
       "\n",
       "       Col_48   Col_49  Col_50  Col_51  Col_52  Col_53  Col_54  Col_55  \\\n",
       "10116  24.669  26.1543  67.082       1  0.0424  1.1564  1.7731    2005   \n",
       "\n",
       "       Col_56  Col_57    Col_58  Col_59  Col_60    Col_61  Col_62  Col_63  \\\n",
       "10116     1.8  0.0756  838.4903     0.0   1.134  0.007164  67.082       2   \n",
       "\n",
       "       Col_64  Col_65  Col_66  Col_67  Col_68   Col_69  Col_70  Col_71  \\\n",
       "10116  0.6653  1.1493   19.98  1.1258   33.12  0.00008    0.45  15.698   \n",
       "\n",
       "       Col_72  Col_73  Col_74  Col_75   Col_76  Col_77  Col_78  Col_79  \\\n",
       "10116  0.7707     0.0     1.0     0.0  0.02838  9108.9    2.43     4.1   \n",
       "\n",
       "        Col_80  Col_81  Col_82   Col_83  Col_84  Col_85  Col_86  Col_87  \\\n",
       "10116  0.00132       4  0.5374  1407.35  0.0044  0.0657    5.28     0.0   \n",
       "\n",
       "        Col_88  Col_89  Col_90   Col_91  Col_92   Col_93  Col_94     Col_95  \\\n",
       "10116  425.192  0.0133    0.99  44.5266  5.5897  10.3882     5.0  1374.1179   \n",
       "\n",
       "       Col_96   Col_97  Col_98  Col_99  Col_100  Col_101  Col_102  Col_103  \\\n",
       "10116     1.0  0.40484       1  8.7115      0.0    1.048    1.064      0.0   \n",
       "\n",
       "       Col_104  Col_105  Col_106  Col_107  Col_108  Col_109  Col_110  Col_111  \\\n",
       "10116        3    1.064    0.224   1.0711      0.0   1.1327     11.7    34.38   \n",
       "\n",
       "       Col_112  Col_113  Col_114  Col_115  Col_116  Col_117  Col_118  Col_119  \\\n",
       "10116   638.55   0.0267   1.0861      1.0        0   2.5556   0.2012   161.19   \n",
       "\n",
       "       Col_120   Col_121  Col_122  Col_123  Col_124  Col_125  Col_126  \\\n",
       "10116     3.78  0.545672   67.082        5   0.0613        2   8.1351   \n",
       "\n",
       "       Col_127  Col_128  Col_129  Col_130    Col_131  Col_132  Col_133  \\\n",
       "10116     6.03   3.2308   6.4568   1.1176  5590.7155   45.688  49.9053   \n",
       "\n",
       "       Col_134  Col_135  Col_136  Col_137  Col_138  Col_139  Col_140  Col_141  \\\n",
       "10116    2.328      0.0     0.45     60.0   1.6222     1402      3.0      0.0   \n",
       "\n",
       "       Col_142  Col_143   Col_144  Col_145  Col_146  Col_147  Col_148  \\\n",
       "10116      0.9   0.0222  0.000268      0.0     0.04   167.13   4.3777   \n",
       "\n",
       "        Col_149  Col_150  Col_151  Col_152  Col_153  Col_154  Col_155  \\\n",
       "10116  0.007428      1.0      4.0   0.9525      0.0     0.72     60.0   \n",
       "\n",
       "       Col_156  Col_157  Col_158  Col_159  Col_160  Col_161  Col_162  Col_163  \\\n",
       "10116      1.0        3     0.72      0.0      0.0   3.3529   3.6522   0.0311   \n",
       "\n",
       "       Col_164  Col_165  Col_166  Col_167  Col_168  Col_169  Col_170  Col_171  \\\n",
       "10116    1.509   1.0699   0.0311     1.26      1.0      1.2   1.0993    0.016   \n",
       "\n",
       "       Col_172  Col_173  Col_174  Col_175  Target  \n",
       "10116      2.0   1.1065   0.1413        4       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.loc[:,attributes].astype(float))\n",
    "y_train = df_train[TARGET].values\n",
    "\n",
    "X_test = scaler.transform(df_test.loc[:,attributes].astype(float))\n",
    "y_test = df_test[TARGET].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Baseline Score\n",
    "Doing this just to get a rough idea of how well the model scores by itself without any new parameters or optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "param_range = np.logspace(-4, 4, 9) \n",
    "\n",
    "param_grid = [{\n",
    "    'solver': ['newton-cg', 'lbfgs', 'saga'],\n",
    "     'C': param_range, \n",
    "    'penalty': ['l1', 'none']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.708958 using {'criterion': 'entropy', 'max_features': 9, 'n_jobs': -1, 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702014 (0.015174) with: {'criterion': 'gini', 'max_features': 9, 'n_jobs': -1, 'random_state': 3}\n",
      "0.705208 (0.016532) with: {'criterion': 'gini', 'max_features': 9, 'n_jobs': -1, 'random_state': 6}\n",
      "0.708958 (0.014473) with: {'criterion': 'entropy', 'max_features': 9, 'n_jobs': -1, 'random_state': 3}\n",
      "0.707951 (0.015175) with: {'criterion': 'entropy', 'max_features': 9, 'n_jobs': -1, 'random_state': 6}\n"
     ]
    }
   ],
   "source": [
    "means = gs_result.cv_results_['mean_test_score']\n",
    "stds = gs_result.cv_results_['std_test_score']\n",
    "params = gs_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring -- `accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring -- `rof_auc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
