{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Churn - Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "plt.style.use(\"seaborn-darkgrid\")\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "DEBUG = True\n",
    "SEED = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for d in ['src','data','output']: os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# utility funciton for typesetting percentages\n",
    "display_fraction = lambda n,d: (n/d*100, n, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load and Prepare the Data \n",
    "\n",
    "I have made a slight change of naming convention which will simply code below - and also avoid mistakes in lab sessions when I rerun cells out of order to demo parts of the code.   Rather than using __df__ to store the full dataset I will use __df_all__, and use __df__ as an alias for various dataset as needed - see [Feature Engineering](#Feature_Engineering). So will try to follow naming convention:\n",
    "\n",
    " * __df__ alias for various datasets (trwated link a tmp variable, more later). \n",
    " * __df_all__ full dataset after loading and prepped (columns renamed, value recoded).\n",
    " * __df_model__ dataset with target and a subset of the original attributes that may appear in model or be used to construct other attributes.\n",
    " * __df_train__ dataset \n",
    " * __df_test__ dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn (3333, 20)\n",
      "States (52, 4)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " * Data set consists of 3333 cases (rows) with 22 attributes (cols) and a single target."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn = pd.read_csv(\"data/churn.csv\")\n",
    "print(\"Churn\", df_churn.shape)\n",
    "df_states = pd.read_csv(\"data/states.csv\")\n",
    "print(\"States\", df_states.shape)\n",
    "\n",
    "df_all = df_churn.merge(df_states, on=\"State\")\n",
    "\n",
    "message = (\" * Data set consists of %d cases (rows) with %s attributes (cols) and a single target.\"  \n",
    "% (df_all.shape[0], df_all.shape[1]-1))\n",
    "Markdown(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pre-Processing Data\n",
    "\n",
    " * Filter features - for simplicity doing next to nothing here, and getting of state information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "target = \"Churn\"\n",
    "\n",
    "attributes = df_all.columns.tolist()\n",
    "attributes.remove(target)\n",
    "for c in [\"Churn\", \"State\", \"Name\", \"Longitude\", \"Latitude\"]: \n",
    "    if c in attributes: attributes.remove(c)\n",
    "\n",
    "df_model = df_all.loc[:, attributes + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    " * To keep a level playing field here, we are not going to perform any feature engineering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 19) (1334, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_model, stratify=df_model[target], test_size=.40, random_state=SEED)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account_Length</th>\n",
       "      <th>Area_Code</th>\n",
       "      <th>Intl_Plan</th>\n",
       "      <th>VMail_Plan</th>\n",
       "      <th>VMail_Message</th>\n",
       "      <th>Day_Mins</th>\n",
       "      <th>Day_Calls</th>\n",
       "      <th>Day_Charge</th>\n",
       "      <th>Eve_Mins</th>\n",
       "      <th>Eve_Calls</th>\n",
       "      <th>Eve_Charge</th>\n",
       "      <th>Night_Mins</th>\n",
       "      <th>Night_Calls</th>\n",
       "      <th>Night_Charge</th>\n",
       "      <th>Intl_Mins</th>\n",
       "      <th>Intl_Calls</th>\n",
       "      <th>Intl_Charge</th>\n",
       "      <th>CustServ_Calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>106</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>81.6</td>\n",
       "      <td>120</td>\n",
       "      <td>13.87</td>\n",
       "      <td>235.6</td>\n",
       "      <td>85</td>\n",
       "      <td>20.03</td>\n",
       "      <td>150.9</td>\n",
       "      <td>113</td>\n",
       "      <td>6.79</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Account_Length  Area_Code  Intl_Plan  VMail_Plan  VMail_Message  \\\n",
       "3219             106        510          0           1             33   \n",
       "\n",
       "      Day_Mins  Day_Calls  Day_Charge  Eve_Mins  Eve_Calls  Eve_Charge  \\\n",
       "3219      81.6        120       13.87     235.6         85       20.03   \n",
       "\n",
       "      Night_Mins  Night_Calls  Night_Charge  Intl_Mins  Intl_Calls  \\\n",
       "3219       150.9          113          6.79        9.9           4   \n",
       "\n",
       "      Intl_Charge  CustServ_Calls  Churn  \n",
       "3219         2.67               1      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalizing and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.loc[:,attributes].astype(float))\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = scaler.transform(df_test.loc[:,attributes].astype(float))\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "### Training &mdash; TODO\n",
    "\n",
    " * Pick any classifier from sklearn (EXCEPT SVC and neural networks for time reasons).\n",
    " * Select hyper-parameters to tune.\n",
    " * Generate parameter search space.\n",
    " * Perform search.\n",
    " \n",
    "Thing I'm looking for:\n",
    "\n",
    " * (Obviously) best score (accuracy)\n",
    " * Mixture of grid and random search\n",
    " * Optional - using hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = np.logspace(-4, 4, 9) \n",
    "\n",
    "param_grid = [{\n",
    "    'solver': ['newton-cg', 'lbfgs', 'saga'],\n",
    "     'C': param_range, \n",
    "    'penalty': ['l1', 'none']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.857762 using {'C': 10.0, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 (0.000000) with: {'C': 0.0001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.0001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.854927 (0.000219) with: {'C': 0.0001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 0.0001, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 0.0001, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 0.0001, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.854927 (0.000219) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 0.001, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 0.001, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 0.001, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.854927 (0.000219) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 0.01, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857260 (0.015933) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 0.1, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 0.1, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857095 (0.019708) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 1.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 1.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 1.0, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857762 (0.019924) with: {'C': 10.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 10.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 10.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 10.0, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 100.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 100.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 100.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 100.0, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 1000.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 1000.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 1000.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 1000.0, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 10000.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.857095 (0.017569) with: {'C': 10000.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.857262 (0.018311) with: {'C': 10000.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.857595 (0.019673) with: {'C': 10000.0, 'penalty': 'none', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "means = gs_result.cv_results_['mean_test_score']\n",
    "stds = gs_result.cv_results_['std_test_score']\n",
    "params = gs_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "model = GNB()\n",
    "model.get_params().keys()\n",
    "\n",
    "param_grid = [{\n",
    "    \"priors\" : [None],\n",
    "    \"var_smoothing\" : np.logspace(0,15, num=250),\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.861261 using {'priors': None, 'var_smoothing': 1.3197203930613752}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier as GPC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "model = GPC()\n",
    "GPC().get_params().keys()\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "\n",
    "param_grid = [{\n",
    "#     'kernel': [kernel], do not uncomment unless you've got \n",
    "    'n_restarts_optimizer':[3],\n",
    "    'random_state':[3],\n",
    "    'multi_class':['one_vs_rest']\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.886947 using {'multi_class': 'one_vs_rest', 'n_restarts_optimizer': 3, 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "\n",
    "model = ABC()\n",
    "ABC().get_params().keys()\n",
    "\n",
    "param_grid = [{\n",
    "    'algorithm': [\"SAMME.R\"],\n",
    "    'random_state': [3],\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.875106 using {'algorithm': 'SAMME.R', 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "KNN().get_params().keys()\n",
    "\n",
    "model = KNN()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_neighbors': [5],\n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'weights':['uniform']\n",
    "}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.889117 using {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "model = DTC()\n",
    "DTC().get_params().keys()\n",
    "\n",
    "\n",
    "param_grid = [{\n",
    "    'criterion':[\"entropy\",\"gini\"],\n",
    "    'max_features':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,15],\n",
    "    'splitter':[\"best\",\"random\"],\n",
    "    'random_state':[125,100,75,50],\n",
    "    \n",
    "\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.915455 using {'criterion': 'entropy', 'max_features': 10, 'random_state': 50, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "model = RFC()\n",
    "RFC().get_params().keys()\n",
    "\n",
    "param_grid = [{\n",
    "    'max_features':[9,12,17],\n",
    "    'n_jobs':[-1],\n",
    "    'criterion':[\"gini\",\"entropy\"],\n",
    "    'random_state':[3,6]\n",
    "#     'max_samples_split':[1,2,3,4],\n",
    "# #     'min_samples_leaf':[1,2,3,4],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.951309 using {'criterion': 'entropy', 'max_features': 9, 'n_jobs': -1, 'random_state': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator as HOE\n",
    "from hpsklearn import random_forest, any_classifier, any_preprocessing, any_sparse_classifier, tfidf\n",
    "from hyperopt import hp, tpe\n",
    "# model=HOE(classifier=\"clf\")\n",
    "\n",
    "\n",
    "estim = HOE(classifier=any_classifier('my_clf'), \n",
    "                            preprocessing=any_preprocessing('tfidf'),\n",
    "                            algo=tpe.suggest,max_evals=20,trial_timeout=300)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.66trial/s, best loss: 0.17000000000000004]\n",
      "100%|██████████| 2/2 [00:00<00:00,  1.36trial/s, best loss: 0.15749999999999997]\n",
      "100%|██████████| 3/3 [05:00<00:00, 300.16s/trial, best loss: 0.15749999999999997]\n",
      " 75%|███████▌  | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "estim.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estim.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "\n",
    "gs_result = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Evaluation (Using Test)\n",
    "\n",
    " * Using best classifier found above with best hyper-parameters fit to data and evaluate against `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model = GNB(priors= None, var_smoothing= 1.3197203930613752)\n",
    "# model = GPC(multi_class= \"one_vs_rest\", n_restarts_optimizer= 2, random_state= 1)\n",
    "# model = KNN(algorithm='auto', n_neighbors= 5, weights='uniform')\n",
    "model = RFC(criterion='entropy', max_features=9, n_jobs=-1,random_state=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm/ np.sum(cm), annot=True, fmt=\".2%\", cmap=\"Blues\");\n",
    "plt.savefig(\"confusion_matrix.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred,  digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
