{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Churn - Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "plt.style.use(\"seaborn-darkgrid\")\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "DEBUG = True\n",
    "SEED = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for d in ['src','data','output']: os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# utility funciton for typesetting percentages\n",
    "display_fraction = lambda n,d: (n/d*100, n, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load and Prepare the Data \n",
    "\n",
    "I have made a slight change of naming convention which will simply code below - and also avoid mistakes in lab sessions when I rerun cells out of order to demo parts of the code.   Rather than using __df__ to store the full dataset I will use __df_all__, and use __df__ as an alias for various dataset as needed - see [Feature Engineering](#Feature_Engineering). So will try to follow naming convention:\n",
    "\n",
    " * __df__ alias for various datasets (trwated link a tmp variable, more later). \n",
    " * __df_all__ full dataset after loading and prepped (columns renamed, value recoded).\n",
    " * __df_model__ dataset with target and a subset of the original attributes that may appear in model or be used to construct other attributes.\n",
    " * __df_train__ dataset \n",
    " * __df_test__ dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn (3333, 20)\n",
      "States (52, 4)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " * Data set consists of 3333 cases (rows) with 22 attributes (cols) and a single target."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn = pd.read_csv(\"data/churn.csv\")\n",
    "print(\"Churn\", df_churn.shape)\n",
    "df_states = pd.read_csv(\"data/states.csv\")\n",
    "print(\"States\", df_states.shape)\n",
    "\n",
    "df_all = df_churn.merge(df_states, on=\"State\")\n",
    "\n",
    "message = (\" * Data set consists of %d cases (rows) with %s attributes (cols) and a single target.\"  \n",
    "% (df_all.shape[0], df_all.shape[1]-1))\n",
    "Markdown(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pre-Processing Data\n",
    "\n",
    " * Filter features - for simplicity doing next to nothing here, and getting of state information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "target = \"Churn\"\n",
    "\n",
    "attributes = df_all.columns.tolist()\n",
    "attributes.remove(target)\n",
    "for c in [\"Churn\", \"State\", \"Name\", \"Longitude\", \"Latitude\"]: \n",
    "    if c in attributes: attributes.remove(c)\n",
    "\n",
    "df_model = df_all.loc[:, attributes + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    " * To keep a level playing field here, we are not going to perform any feature engineering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 19) (1334, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_model, stratify=df_model[target], test_size=.40, random_state=SEED)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account_Length</th>\n",
       "      <th>Area_Code</th>\n",
       "      <th>Intl_Plan</th>\n",
       "      <th>VMail_Plan</th>\n",
       "      <th>VMail_Message</th>\n",
       "      <th>Day_Mins</th>\n",
       "      <th>Day_Calls</th>\n",
       "      <th>Day_Charge</th>\n",
       "      <th>Eve_Mins</th>\n",
       "      <th>Eve_Calls</th>\n",
       "      <th>Eve_Charge</th>\n",
       "      <th>Night_Mins</th>\n",
       "      <th>Night_Calls</th>\n",
       "      <th>Night_Charge</th>\n",
       "      <th>Intl_Mins</th>\n",
       "      <th>Intl_Calls</th>\n",
       "      <th>Intl_Charge</th>\n",
       "      <th>CustServ_Calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>106</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>81.6</td>\n",
       "      <td>120</td>\n",
       "      <td>13.87</td>\n",
       "      <td>235.6</td>\n",
       "      <td>85</td>\n",
       "      <td>20.03</td>\n",
       "      <td>150.9</td>\n",
       "      <td>113</td>\n",
       "      <td>6.79</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Account_Length  Area_Code  Intl_Plan  VMail_Plan  VMail_Message  \\\n",
       "3219             106        510          0           1             33   \n",
       "\n",
       "      Day_Mins  Day_Calls  Day_Charge  Eve_Mins  Eve_Calls  Eve_Charge  \\\n",
       "3219      81.6        120       13.87     235.6         85       20.03   \n",
       "\n",
       "      Night_Mins  Night_Calls  Night_Charge  Intl_Mins  Intl_Calls  \\\n",
       "3219       150.9          113          6.79        9.9           4   \n",
       "\n",
       "      Intl_Charge  CustServ_Calls  Churn  \n",
       "3219         2.67               1      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalizing and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.loc[:,attributes].astype(float))\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = scaler.transform(df_test.loc[:,attributes].astype(float))\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9077961019490255\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(X_train, y_train):\n",
    "    n = X_train.shape[0]\n",
    "    sample_idx = np.random.choice(n, size=n,replace=True)\n",
    "    \n",
    "    return X_train[sample_idx], y_train[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "sample_idx = np.random.choice(n,size=n,replace=True)\n",
    "len(set(sample_idx)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 44\n",
    "models = [None] * M\n",
    "for m in range(M):\n",
    "    models[m] = DecisionTreeClassifier()\n",
    "    X_train_sample, y_train_sample = generate_sample(X_train,y_train)\n",
    "    models[m].fit( X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " DecisionTreeClassifier()]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vote = np.zeros( (M, y_test.shape[0]) )\n",
    "for m in range(M):\n",
    "    y_vote[m] = models[m].predict(X_test)\n",
    "y_pred = (y_vote.sum(axis=0) > M//2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95952023988006\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example use of Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'Account_Length', 'Area_Code', 'Intl_Plan', 'VMail_Plan',\n",
       "       'VMail_Message', 'Day_Mins', 'Day_Calls', 'Day_Charge', 'Eve_Mins',\n",
       "       'Eve_Calls', 'Eve_Charge', 'Night_Mins', 'Night_Calls', 'Night_Charge',\n",
       "       'Intl_Mins', 'Intl_Calls', 'Intl_Charge', 'CustServ_Calls', 'Churn',\n",
       "       'Latitude', 'Longitude', 'Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_1 = [\"Account_Length\",\"VMail_Message\",\"Day_Mins\",\"Day_Calls\",\"Day_Charge\",\"Eve_Mins\",\"Eve_Calls\",\"Eve_Charge\",\"Night_Mins\",\"Night_Calls\",\"Night_Charge\",\"Intl_Mins\",\"Intl_Calls\",\"Intl_Charge\",\"CustServ_Calls\"]\n",
    "numeric_features_2 = ['Account_Length']\n",
    "\n",
    "categorical_features = ['Area_Code',\"Intl_Plan\",\"VMail_Plan\"]\n",
    "features =  numeric_features_1 + categorical_features\n",
    "target = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_all[features], df_all[target],train_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('numeric_features_1',preprocessing.StandardScaler(),numeric_features_1),\n",
    "    ('numeric_features_2',preprocessing.StandardScaler(),numeric_features_2),\n",
    "    ('categorica_featutes',preprocessing.OneHotEncoder(),categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('column_transformer',column_transformer ),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8973013493253373"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Evaluation (Using Test)\n",
    "\n",
    " * Using best classifier found above with best hyper-parameters fit to data and evaluate against `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm/ np.sum(cm), annot=True, fmt=\".2%\", cmap=\"Blues\");\n",
    "plt.savefig(\"confusion_matrix.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred,  digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
